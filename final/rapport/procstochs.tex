\subsection{Introduction -- Chaines de Markov}
  Un processus stochastique représente l'évolution au cours du temps d'une
  variable aléatoire. Dans cette section, nous étudierons particulièrement les
  processus de Markov, qui sont des processus stochastiques dont l'état futur
  ne dépend pas des états passés.

  Enfin, une chaine de Markov est un processus de Markov à temps discret. On
  peut la représenter sous forme d'un graphe, dont les sommets représentent des
  états et les arêtes des transitions d'un état à l'autre.

\subsection{Colonie de scarabées}
  Le problème consiste, à partir d'un graphe dont les nœuds représentent des
  positions et les arêtes contiennent la probabilité pour un scarabée de passer
  d'une position à l'autre, à calculer les probabilités de présence de chaque
  scarabée au bout de $N$ itérations, selon sa position de départ.

  Pour cela, on représente le graphe sous la forme de matrice d'adjacence, où
  chaque élément de la matrice représente la probabilité de passer d'un nœud à
  un autre.

  Si on met cette matrice à la puissance $N$, elle contiendra les probabilités
  de passer d'un nœud à un autre en exactement $N$ itérations.

  En multipliant cette matrice par un vecteur contenant uniquement des zéros,
  sauf au nœud de départ (on mettra un 1), on peut obtenir la probabilité pour
  le scarabée de se trouver à chaque point, au bout d'exactement $N$ tours.  Si
  cette probabilité est nulle, il est impossible qu'il s'y trouve.

  Pour savoir la probabilité que les deux scarabées se rencontrent en un point
  au bout de $N$ itérations, il suffit de multiplier les probabilités de
  présence de chaque scarabée en ce point. Pour connaitre leur probabilité de se
  rencontrer en n'importe quel point, on peut tout simplement sommer les
  probabilités de rencontre sur chaque point.

  De plus, si on calcule $\lim_{N \to \infty} A^N$ (une telle limite n'existera
  que si la chaine est irréductible, récurrente positive et apériodique, et ça
  ne sera pas toujours le cas!), le produit du vecteur avec la position de
  départ par cette matrice nous donnera les probabilités pour le scarabée
  d'être en chaque position une fois qu'il aura suffisamment voyagé et que sa
  position de départ n'aura plus d'importance.
  %TODO: c'est quoi une chaine irréductible blabla apériodique?

  \subsubsection{Chaines de Markov}
    Le problème des scarabées peut aisément être modélisé par des chaines de
    Markov. En effet, nos coléoptères se promènent en temps discret dans leur
    graphe de promenade; de plus, l'état d'un scarabée (autrement dit, sa
    position dans sa promenade) ne dépend pas du passé, mais uniquement de
    l'état présent.

    La matrice de transition de notre promenade représente les probabilités de
    passer d'un état aux autres. Par conséquent, la matrice de transition à la
    puissance $n$ représente la probabilité de passer d'un état à un autre par
    un chemin de longueur $n$.

    On constate qu'on se rapproche beaucoup de la matrice décrite précédemment:
    la matrice d'adjacence du graphe de promenade et la matrice de transition
    de notre chaine de Markov sont équivalentes!

  \subsubsection{Temps moyen entre rencontres}
    \paragraph{À partir d'un certain point}
      Considérons que les deux scarabées sont sur le même point.  On peut donc
      calculer la probabilité qu'après $N$ tours, ils finissent à nouveau sur
      la même case (en sommant le carré des probabilités que chacun se retrouve
      sur une case).

      Notons $U_k = pA^k(pA^k)^\intercal$ la probabilité que les deux scarabées
      se retrouvent sur la même case après $k$ tours.

      Notons $V_k$ la probabilité que les deux scarabées se retrouvent sur la
      même case après $k$ tours, sans s'être déjà rencontrés avant. On a:
        \[V_k = (1 - U_1) \times (1 - U_2) \times \cdots \times (1 - U_{k - 1})
        \times U_k\]

      $V_k$ peut donc se réécrire par récurrence:
        \begin{align*}
          V_1       &= U_1 \\
          V_{k + 1} &= V_k \times \frac{1 - U_k}{U_k}U_{k + 1}
        \end{align*}

      Pour avoir le temps moyen au bout duquel ils vont se rencontrer en
      partant de ce même point, il suffit de prendre l'espérance de cette suite
      $V_k$. %TODO: qui est?

    \paragraph{À partir de deux points différents}
      Dans le cas où les points de départs des scarabées sont différents, on peut
      appliquer le même principe.

      Par contre, on ne peut pas supposer $U_k \neq 0$.
      On peut introduire une suite $W_k$:
      \begin{align*}
        W_0 &= 1 \\
        W_k &= W_{k-1} \times (1 - U_k)
      \end{align*}

      On a donc:
      \begin{align*}
        V_1  &= U_1 \\
        V_k &= W_{k-1} \times U_k
      \end{align*}

      Pour avoir un temps moyen de rencontre global, on fait la moyenne du temps
      de rencontre pour chaque position initiale possible. %TODO: qui est?

  \subsubsection{Exemple}
    Partons du graphes suivant:
    \begin{center}
      \begin{tikzpicture}[->, >=stealth', shorten >=1pt, auto]
        \node[draw, circle] (1) at (0, 0) {1};
        \node[draw, circle] (2) at (-2.8, 4) {2};
        \node[draw, circle] (3) at (2.8, 4) {3};

        \path (2) edge [bend left=10, -triangle 90] node {$\frac 1 3$} (1);
        \path (1) edge [bend left=10, -triangle 90] node {$\frac 1 4$} (2);
        \path (3) edge [bend left=10, -triangle 90] node {$\frac 1 2$} (1);
        \path (1) edge [bend left=10, -triangle 90] node {$\frac 3 4$} (3);
        \path (3) edge [-triangle 90] node {$\frac 1 2$} (2);
        \path (2) edge [-triangle 90] node {} (3);
      \end{tikzpicture}
    \end{center}

    La matrice d'adjacence de ce graphe est:
      \[A = \left(\begin{array}{ccc}
        0 & \frac 1 3 & \frac 1 2 \\
        \frac 1 4 & \frac 1 6 & \frac 1 2 \\
        \frac 3 4 & \frac 1 2 & 0
      \end{array}\right)\]

    Si on veut connaitre la probabilité qu'un scarabée se trouve au sommet 2 en
    partant du sommet 1 sur 10 tours, on calcule:
      \[
        \left(\begin{array}{ccc}
          0 & \frac 1 3 & \frac 1 2 \\
          \frac 1 4 & \frac 1 6 & \frac 1 2 \\
          \frac 3 4 & \frac 1 2 & 0
        \end{array}\right)^{10}
        \times
        \left(\begin{array}{c}
          1 \\ 0 \\ 0
        \end{array}\right)
        \approx
        \left(\begin{array}{c}
          0.30188 \\ 0.32244 \\ 0.37568
        \end{array}\right)
      \]

    La probabilité voulue est donc $0.32244$.

    \paragraph{}
    De plus, on remarque que $A^n$ converge vers
      \[
        \left(\begin{array}{ccc}
          0.29787 & 0.29787 & 0.29787 \\
          0.31915 & 0.31915 & 0.31915 \\
          0.38298 & 0.38298 & 0.38298
        \end{array}\right)
      \]
    lorsque $n \to +\infty$, donc quelque soit la position de départ du
    scarabée, après un nombre suffisant de tours, la probabilité qu'il soit sur
    le sommet 2 est $0.31915$.

    %todo: temps moyen

\subsection{Théorie des files d'attente}
  Une file d'attente est un système ayant une entrée par laquelle arrivent des
  tâches, ou client, qui attendent leur tour avant d'être traitée une pour en
  sortir.

  Elles sont utilisées pour l'étude de beaucoup de systèmes: attentes de
  clients à des guichets, trafic routier, traitement des tâches par un
  serveur, etc.

  \paragraph{}
  Les files sont étudiées en fonction de la loi qui gère l'entrée, la loi qui
  gère la sortie et le nombre de ``serveurs'' qui traitent les clients.

  La loi de Little est cependant un résultat général:
    \[N = \lambda T_s\]
  où $N$ est le nombre moyen de clients dans le système, $\lambda$ la fréquence
  moyenne d'entrée et $T_s$ le temps moyen passé dans le système.

  \subsubsection{Cas M/M/1}
    On considère une file d'attente où la loi d'entrée suit une loi de Poisson
    de paramètre $\lambda$ ($\lambda$ est dont le nombre moyen d'arrivées par
    unité de temps) et que le temps de service suit une loi exponentielle de
    paramètre $\mu$ ($\frac 1 \mu$ est donc le temps moyen de traitement, sans
    compter l'attente dans la file).

    On dit que ce genre de file d'attente est de type $M/M/1$ selon les
    notations de Kendall.

    Dans ce cas, le nombre moyen d'arrivées pendant le temps de service, appelé
    trafic offert, est $\rho = \frac \lambda \mu$. Le système converge alors si
    et seulement si $\rho < 1$.
    
    \paragraph{}
    La file peut être représentée comme une chaine de Markov où chaque état $i$
    représente la probabilité qu'il y ait $i$ voitures dans le système (voir
    figure~\ref{fig:markov1}).

    \begin{figure}[h]
      \centering
      \begin{tikzpicture}[->,shorten >=1pt,auto,node distance=2cm,semithick]
        \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=1.1cm]

        \node[state] (A) {0};
        \node[state] (B) [right of=A] {$1$};
        \node[state] (C) [right of=B] {$2$};
        \node[state] (D) [right of=C] {$3$};
        \node[minimum size=1cm] (E) [right of=D] {$\cdots$};

        \path (A) edge [bend left] node {$\lambda$} (B);
        \path (B) edge [bend left] node {$\mu$} (A);
        \path (B) edge [bend left] node {$\lambda$} (C);
        \path (C) edge [bend left] node {$\mu$} (B);
        \path (C) edge [bend left] node {$\lambda$} (D);
        \path (D) edge [bend left] node {$\mu$} (C);
        \path (D) edge [bend left] node {$\lambda$} (E);
        \path (E) edge [bend left] node {$\mu$} (D);
      \end{tikzpicture}
      \caption{Représentation d'une file M/M/1 comme une chaine de Markov
        \cite{procstochs_cc}}
      \label{fig:markov1}
    \end{figure}

    Ces états sont liés en régime permanent par les équations:
      \[
        \left\{\begin{aligned}
          \lambda p_0 & = \mu p_1 \\
          \lambda p_1 & = \mu p_2 \\
          & \cdots \\
          \lambda p_n & = \mu p_{n+1} \\
          & \cdots 
        \end{aligned}\right.
      \]
    et
      \[
        \sum_{i=0}^{+\infty} p_n = 1
      \]

    D'où $p_n = \left(\frac \lambda \mu\right)^n p_0 =
     \left(\frac \lambda \mu\right)^n \left(1-\frac \lambda \mu\right) =
     \rho^n (1-\rho)$ (d'où la condition $\rho < 1$).

   Le nombre moyen de clients dans le système est donc:
     \[ N = \sum_{i=0}^n np_n = \frac \rho {1-\rho} \]

   D'après la loi de Little, le temps moyen passé dans le système est donc:
     \[
       T_s = \frac 1 \lambda \frac \rho {1-\rho}
           = \rho \frac \lambda {\mu-\lambda}
     \]

  \subsubsection{Cas M/M/S}
    Une généralisation du cas précédent sont les files de type $M/M/S$, où $S$
    dénote le nombre de serveurs. Les lois d'entrée et sortie restent les mêmes.

    Ces files peuvent aussi être représentées avec les chaines de Markov (voir
    figure~\ref{fig:markov2}).

    \begin{figure}[h]
      \centering
      \makebox[\textwidth]{\begin{tikzpicture}
        [->,shorten >=1pt,auto,node distance=2cm,semithick]
        \tikzstyle{every state}=[fill=white,draw=black,text=black,minimum size=1.1cm]

        \node[state] (A) {0};
        \node[state] (B) [right of=A] {$1$};
        \node[state] (C) [right of=B] {$2$};
        \node[state] (D) [right of=C] {$3$};
        \node[minimum size=1cm] (E) [right of=D] {$\cdots$};
        \node[state] (F) [right of=E] {$S-1$};
        \node[state] (G) [right of=F] {$\phantom{+}S\phantom{+}$};
        \node[state] (H) [right of=G] {$S+1$};
        \node[minimum size=1cm] (I) [right of=H] {$\cdots$};

        \path (A) edge [bend left] node {$\lambda$} (B);
        \path (B) edge [bend left] node {$\mu$} (A);
        \path (B) edge [bend left] node {$\lambda$} (C);
        \path (C) edge [bend left] node {$2\mu$} (B);
        \path (C) edge [bend left] node {$\lambda$} (D);
        \path (D) edge [bend left] node {$3\mu$} (C);
        \path (D) edge [bend left] node {$\lambda$} (E);
        \path (E) edge [bend left] node {$4\mu$} (D);
        \path (E) edge [bend left] node {$\lambda$} (F);
        \path (F) edge [bend left] node {$(S-1)\mu$} (E);
        \path (F) edge [bend left] node {$\lambda$} (G);
        \path (G) edge [bend left] node {$S\mu$} (F);
        \path (G) edge [bend left] node {$\lambda$} (H);
        \path (H) edge [bend left] node {$S\mu$} (G);
        \path (H) edge [bend left] node {$\lambda$} (I);
        \path (I) edge [bend left] node {$S\mu$} (H);
      \end{tikzpicture}}
      \caption{Représentation d'une file M/M/S comme une chaine de Markov
        \cite{procstochs_cc}}
      \label{fig:markov2}
    \end{figure}

    L'étude de ces chaines est plus compliquée car les états ne sont plus liés
    par la même équation:
      \[
        \left\{\begin{aligned}
          \lambda p_0 & = \phantom{2\times~}\mu p_1 \\
          \lambda p_1 & = 2\times\mu p_2 \\
          & \cdots \\
          \lambda p_{S-2} & = (S-1)\times\mu p_{S-1} \\
          \lambda p_{S-1} & = S\times\mu p_S \\
          \lambda p_S & = S\times\mu p_{S+1} \\
          \lambda p_{S+1} & = S\times\mu p_{S+2} \\
          & \cdots 
        \end{aligned}\right.
      \]

    On peut montrer que le système est en équilibre si et seulement si
    $\rho = \frac \lambda {S\mu} < 1$. Le nombre moyen de clients et temps
    moyen dans le système sont par contre beaucoup moins intuitifs:
    \[
      \begin{aligned}
        N   &= \rho \left(1 + \frac{P_a}{S-\rho}\right) \\
        T_s &= \frac{1}{\mu} \left(1 + \frac{P_a}{S-\rho}\right)
      \end{aligned}
    \]
    où $\displaystyle P_a = P_0 \frac{\rho^S}{(S-1)!(S-\rho)}$ est la
    probabilité d'attendre et $\displaystyle P_0 = \frac{1}{\sum_{k=0}^{S-1}
    \frac{\rho^k}{k!} + \frac {\rho^S}{S!} \frac {1}{1-\rho/S} }$ est la
    probabilité que le système soit vide.

    On remarque qu'on retrouve bien les mêmes résultats que précédement pour
    $S=1$.

