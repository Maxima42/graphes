\subsection{Introduction}
  La programmation linéaire, ou optimisation linéaire, consiste à maximiser (ou
  de manière équivalente minimiser) une fonction linéaire sur un polyèdre
  convexe (dont un cas particulier courant est sous des contraintes linéaires).

\subsection{Problème du sac à dos}
  \subsubsection{Présentation du problème}
    \begin{center}\includegraphics[width=120pt]{sac_a_dos.jpg}\end{center}

    Ce problème paraît simple en apparence: nous avons un ensemble d'objets,
    chaque objet pouvant avoir une masse différente et ayant une certaine
    valeur, et nous voulons remplir un sac à dos de manière à maximiser la
    valeur totale, sans dépasser une certaine masse maximale.

    Résoudre ce genre de problème est utile par exemple en gestion de
    portefeuilles pour trouver le meilleur rapport entre rendement et risque,
    ou en découpe de matériaux, pour minimiser les chutes.

    \paragraph{}
    Ce problème est un problème d'optimisation linéaire, en effet, cela revient
    à résoudre le problème:
    \[ \begin{array}{r|l}
        \displaystyle\max_{i \in S' \subset S} v_i &
        \displaystyle\sum_{i \in S'} m_i \leq W
      \end{array}
    \]
    où $S$ est l'ensemble des objets, $S'$ est un ensemble de $n$ objets
    choisis, $v_i$ la valeur de l'objet $i \in S$, $m_i$ sa masse et $W$ la
    masse maximale autorisée dans le sac.

    Cependant la résolution de ce problème n'est pas simple: déterminer s'il
    est possible de dépasser une valeur minimale sans dépasser le poids maximal
    est un problème NP\nobreakdash-complet.

  \subsubsection{Résolution exacte}
    Une exploration exhaustive de l'ensemble des parties de $S$ n'est pas très
    réaliste, car celui-ci est de cardinal $2^{\mathrm{card} S}$.

    Mais, ce problème peut être résolu en utilisant la programmation
    dynamique\footnote{Qui consiste à résoudre un problème de taille $n$ à
    partir de la résolution d'un problème de taille $n-1$}. En effet, on peut
    déterminer si un objet $i$ fait partie de l'ensemble des objets à choisir en
    considérant le problème sur l'ensemble $S\backslash\{i\}$ et la masse
    maximale $W-m_i$.
    
    Toutefois, un tel algorithme (voir algorithme~\ref{alg:sacados}) fonctionne
    uniquement si les poids des objets
    sont des entiers. De plus sa complexité en temps est en $O(nW)$ et celle en
    mémoire en $O(W)$\footnote{En pratique on pourrait l'utiliser sur des
    masses non-entières en les multipliant, ce qui augmenterait la complexité
    du même facteur. De plus on peut réduire la complexité temporelle en
    $O(nW')$ avec $W' = \frac W {\mathrm{ppcm}(\text{toutes les masses})}$.}.

    \begin{algorithm}
      \KwIn{une liste d'objets}
      \KwIn{une masse maximale autorisée}
      \KwOut{la valeur maximale qu'il est possible d'atteindre}
      \Begin{%
        ligne\_courante = liste composée de (masse\_max+1) zéros\;
        ligne\_prec     = liste composée de (masse\_max+1) zéros\;
        \For{chaque objet obj de la liste d'entrée}{%
          \For{m variant de 0 à masse\_max}{%
            \If{masse(obj) $\leq$ m}{%
              ligne\_courante[m] $\leftarrow$ max(ligne\_prec[m], ligne\_prec\_line[m-masse(obj)] + prix(obj))\;
            }
          }
          ligne\_prec $\leftarrow$ ligne\_courante
        }
        \Return{ligne\_courante[masse\_max]}
      }
      \caption{Algorithme de résolution exacte du problème du sac à dos}
      \label{alg:sacados}
    \end{algorithm}

  \subsubsection{Résolution approchée}
    Un autre algorithme pour résoudre ce problème, dit algorithme glouton,
    consiste simplement à choisir les «~meilleurs~» objets jusqu'à que la masse
    maximale soit dépassée. Le critère déterminant quels sont les meilleurs
    objets pourrait être la masse faible, le prix élevé, ou le rapport
    prix/masse élevé.

    % FIXME: Osef des tests ? Ça explique pas en détail, mais c'est trop expérimental je trouve
    Cet algorithme est beaucoup plus rapide que le précédent (il a une
    complexité en temps de $O(n \log n)$ (pour le tri des objets)) et ne
    nécessite en mémoire que la liste des objets, mais ce n'est qu'un algorithme
    approché. Les résultats obtenus sont cependant très satisfaisant, en effet
    en considérant le ratio \nobreak prix/masse, on obtient des résultats très
    proches de l'optimum (quelques pourcents d'erreur relative en moyenne, mais
    aucune garantie n'est fournie: il peut même fournir la pire solution).

    De plus il peut être utilisé quand les masses ne sont pas entières.

    \paragraph{}
    Un autre algorithme pour résoudre ce problème est inspiré du comportement
    des fourmis: une ``fourmi'' se promène plus ou moins au hasard dans
    l'ensemble des possibilités en marquant les objets choisis comme
    intéressants (comme les fourmis le font avec les phéromones). Ces fourmis
    vont essayer de choisir de plus en plus souvent les objets ayant souvent
    été marqués intéressants. On s'arrête après un certain nombre de tours ou
    quand les nouvelles itérations ne sont plus considérés suffisamment
    intéressantes.

  \subsubsection{Rapport avec le voyageur de commerce}
    Il est intéressant ici de faire le lien avec le problème du voyageur
    du commerce: les solutions utilisées ici sont \textbf{les mêmes}.

    En effet, on a vu que ce problème (avec des poids non entiers, donc impossible
    à résoudre par programmation dynamique) se résout seulement par une recherche
    exhaustive.
    
    On a aussi vu comment le résoudre de manière approchée via un heuristique
    simple, et l'algorithme des fourmis est une métaheuristique qu'on a mentionnée
    précédemment.


    Plus intéressant encore, on peut même construire une «~bijection~» entre un problème du sac à dos
    et un problème du voyageur de commerce sur un graphe ! \cite{knapsack_to_tsp}
    Ceci démontre que ces deux algorithmes sont équivalents, et appartiennent donc à la même
    classe d'algorithmes. % c'est bôoooo les maths :D


\subsection{Problème d'optimisation linéaire}
  Le but du problème est de maximiser une fonction linéaire sous certaines
  contraintes, linéaires elles aussi.

  \subsubsection{Point de vu mathématique} % todo: titre?
      Considérons le problème suivant :
      $$ (P) \quad \max_{x\in C \subset \mathbb{R}^n} f(x)$$
      Nous nous placerons dans le cas où $f$ est linéaire, où $x \geqslant 0$,
      et où $C$ est décrit par des contraintes d'inégalités linéaires,
      c'est-à-dire qu'il existe une matrice $A$ et un vecteur $b$ tels
      que $Ax\leqslant b$.

    \paragraph{Existence de solutions}
      Pour un tel problème, trois possibilités s'offrent à nous:
      \begin{itemize}
        \item les contraintes sont incompatibles;
        \item la fonction est non majorée sur $C$;
        \item le problème admet un maximum sur $C$.
      \end{itemize}
      Nous savons de plus que $C$ est un polyèdre convexe. Un théorème garantit
      alors que si ce problème à une solution, alors il a une solution en un de
      ses sommets. Nous allons donc chercher les solutions parmi les sommets de
      $C$.

  \subsubsection{Algorithme du simplexe}
    Le principe de cet algorithme est de considérer un des sommets du polyèdre,
    puis de se déplacer en suivant les arêtes de ce polyèdre en augmentant à
    chaque itération le gain. L'algorithme se terminera lorsque nous nous 
    trouverons sur un sommet, dont tous les sommets adjacents présentent un gain
    plus faible. La convexité du polyèdre nous garantit que le résultat est 
    optimal.

    L'algorithme du simplexe a une complexité dans le pire des cas
    exponentielle, mais en pratique, cet algorithme est efficace.
    
    Cet algorithme ne permet pas de maximiser une fonction pour des variables
    entières (par exemple pour connaitre un nombre de produits à produire, donc
    un nombre entier) à produire pour maximiser un gain (bien qu'on pourrait en
    pratique l'utiliser en considérant que la solution optimale entière est
    suffisamment proche de la solution optimale réelle).

    \paragraph{Forme standard et tableau canonique}
      Pour résoudre le problème, la première étape est le mettre sous forme
      standard. Pour cela on ajoute à chaque inéquation $j$ de la forme
      $\sum a_{j,i}x_i \leq 0$ une variable dite d'écart pour la transformer en
      égalité: $\sum a_{j,i}x_i + s_j = 0$ où $s_j \geq 0$.
      
      Les inéquations de la forme $\sum a_ix_i \geq 0$ sont d'abord multipliées
      par $-1$ avant cette étape.
      %todo: et les égalités on en fait quoi ? J'ai essayé en les transformant
      %en deux inégalités <= et >= mais ça marche pas.

      On construit ensuite un tableau dit canonique représentant le problème
      comme suit:
      \begin{itemize}
        \item la première ligne de la matrice est
          $[m_0, m_1, \cdots, m_n, 0, \cdots, 0]$ où les $(m_i)$ sont les
          coefficients du problème $\min \sum m_ix_i$ et à laquelle on ajoute
          autant de $0$ qu'on a ajouté de variables d'écart;
        \item les autres lignes de la matrice sont
          $[a_{j,0}, \cdots, a_{j,n}, 0, \cdots, 0, 1,0, \cdots, 0]$ où les $1$
          sont placés de manière à former une matrice identité (ils
          correspondent aux variables d'écart ajoutées).
      \end{itemize}

      %todo: algorithmiser
      \begin{lstlisting}
Entrée : matrice (un tableau canonique)
Sortie : le résultat optimum
         les quantités de chaque produit à produire
         les quantités de chaque ressource restante

base = indices des variables de base de la matrice

tant qu'il reste des nombres strictement positifs sur la première ligne:
    à_ajouter = indice de la colonne dont le premier élément est maximal
    à_retirer = indice de la ligne (>1) telle que :
                matrice[à_retirer, dernière colonne]/matrice[à_retirer, à_ajouter]
                est minimum

    remplacer le (à_retirer)ième élément de base par à_ajouter

    diviser la ligne à_retirer de matrice par matrice[à_retirer, à_ajouter]
    et soustraire aux autres lignes y le vecteur :
        matrice[y,à_ajouter] * matrice[à_retirer,] / matrice[à_retirer, à_ajouter]

pour chaque variable d'origine n (n dans [0, nombre de variables hors base[):
  à_produire[base[n]] = matrice[n+1, dernière colonne]

pour chaque variable d'écart n (n dans [nombre de variables hors base, nombre de variables total[):
  restes[base[n]] = matrice[n+1, dernière colonne]

retourner (-matrice[0, dernière colonne], à_produire, restes)
      \end{lstlisting}

    % todo:
    %       contraintes négatives
    %       cas non borné
    \paragraph{Dégénérescence}
      Un problème du simplexe est dit dégénéré si plus de deux contraintes vont
      devoir être nulles en un sommet. Graphiquement, cela veut dire
      qu'au moins 3 droites vont se rencontrer en un sommet du polyèdre.

      Ceci va empêcher l'algorithme du simplexe de progresser entre deux
      itérations: il va simplement changer de base. Le problème étant que sur
      des cas particuliers, il pourra changer de base sans progresser, puis
      boucler à l'infini en faisant un cycle sur des bases qui n'améliorent pas
      la solution.

      Pour éviter cela, on pourrait utiliser des règles d'anti-cyclage, dont la
      règle de Bland, qui consiste à choisir judicieusement les variables qu'on
      fera entrer et sortir de la base, dans le cas où il y aurait plusieurs
      possibilités aussi intéressantes les unes que les autres.

