\subsection{Introduction}
  La programmation linéaire, ou optimisation linéaire, consiste à maximiser (ou,
  de manière équivalente, minimiser) une fonction linéaire sur un polyèdre
  convexe (dont un cas particulier courant est la maximisation sous des 
  contraintes linéaires).

\subsection{Problème du sac à dos}
  \subsubsection{Présentation du problème}
    \begin{center}\includegraphics[width=120pt]{sac_a_dos.jpg}\end{center}

    Ce problème parait simple en apparence: nous avons un ensemble d'objets,
    chaque objet pouvant avoir une masse différente et ayant une certaine
    valeur, et nous voulons remplir un sac à dos de manière à maximiser la
    valeur totale, sans dépasser une certaine masse maximale.

    Résoudre ce genre de problèmes est utile par exemple en gestion de
    portefeuilles pour trouver le meilleur rapport entre rendement et risque,
    ou en découpe de matériaux, pour minimiser les chutes.

    \paragraph{}
    Ce problème est un problème d'optimisation linéaire. En effet, cela revient
    à résoudre le problème:
    \[ \begin{array}{r|l}
        \displaystyle\max_{i \in S' \subset S} v_i &
        \displaystyle\sum_{i \in S'} m_i \leq W
      \end{array}
    \]
    où $S$ est l'ensemble des objets, $S'$ est un ensemble de $n$ objets
    choisis, $v_i$ la valeur de l'objet $i \in S$, $m_i$ sa masse et $W$ la
    masse maximale autorisée dans le sac.

    Cependant la résolution de ce problème n'est pas simple: déterminer s'il
    est possible de dépasser une valeur minimale sans dépasser le poids maximal
    est un problème NP\nobreakdash-complet.

  \subsubsection{Résolution exacte}
    Une exploration exhaustive de l'ensemble des parties de $S$ n'est pas très
    réaliste, car celui-ci est de cardinal $2^{\mathrm{card} S}$.

    Mais, ce problème peut être résolu en utilisant la programmation
    dynamique\footnote{Qui consiste à résoudre un problème de taille $n$ à
    partir de la résolution d'un problème de taille $n-1$.}. En effet, on peut
    déterminer si un objet $i$ fait partie de l'ensemble des objets à choisir en
    considérant le problème sur l'ensemble $S\backslash\{i\}$ et la masse
    maximale $W-m_i$.
    
    Toutefois, un tel algorithme (voir algorithme~\ref{alg:sacados}) fonctionne
    uniquement si les poids des objets
    sont des entiers. De plus sa complexité en temps est en $O(nW)$ et celle en
    mémoire en $O(W)$\footnote{En pratique on pourrait l'utiliser sur des
    masses non-entières en les multipliant, ce qui augmenterait la complexité
    du même facteur. De plus on peut réduire la complexité temporelle en
    $O(nW')$ avec $W' = \frac W {\mathrm{ppcm}(\text{toutes les masses})}$.}.

  \subsubsection{Résolution approchée}
    Un autre algorithme pour résoudre ce problème, dit algorithme glouton,
    consiste simplement à choisir les «~meilleurs~» objets jusqu'à que la masse
    maximale soit dépassée. Le critère déterminant quels sont les meilleurs
    objets pourrait être la masse faible, le prix élevé, ou le rapport
    prix/masse élevé.

    Cet algorithme est beaucoup plus rapide que le précédent (il a une
    complexité en temps de $O(n \log n)$, pour le tri des objets) et ne
    nécessite en mémoire que la liste des objets. De plus il peut être utilisé
    quand les masses ne sont pas entières. Mais ce n'est qu'un algorithme
    approché qui ne fournit aucune garantie de résultat.


    \paragraph{}
    Un autre algorithme pour résoudre ce problème est inspiré du comportement
    des fourmis: une ``fourmi'' se promène plus ou moins au hasard dans
    l'ensemble des possibilités en marquant les objets choisis comme
    intéressants (comme les fourmis le font avec les phéromones). Ces fourmis
    vont essayer de choisir de plus en plus souvent les objets ayant souvent
    été marqués intéressants. On s'arrête après un certain nombre de tours, ou
    quand les nouvelles itérations ne sont plus considérées suffisamment
    intéressantes.

  \subsubsection{Relation avec le voyageur de commerce}
    Il est intéressant ici de faire le lien avec le problème du voyageur
    du commerce: les solutions utilisées ici sont \emph{les mêmes}.

    En effet, on a vu que ce problème (avec des poids non entiers, donc impossible
    à résoudre par programmation dynamique) se résout seulement par une recherche
    exhaustive.
    
    On a aussi vu comment le résoudre de manière approchée via une heuristique
    simple, et l'algorithme des fourmis est une métaheuristique qu'on a mentionnée
    précédemment.


    Plus intéressant encore, on peut même construire une «~bijection~» entre un
    problème du sac à dos
    et un problème du voyageur de commerce sur un graphe\cite{knapsack_to_tsp}!
    Ceci démontre que ces deux algorithmes sont équivalents, et appartiennent donc à la même
    classe d'algorithmes. % c'est bôoooo les maths :D

\subsection{Problème d'optimisation linéaire}
  Le but du problème est de maximiser une fonction linéaire sous certaines
  contraintes, linéaires elles aussi.

  \subsubsection{Point de vue mathématique}
      Considérons le problème suivant :
      $$ (P) \quad \max_{x\in C \subset \mathbb{R}^n} f(x)$$
      Nous nous placerons dans le cas où $f$ est linéaire, où $x \geqslant 0$,
      et où $C$ est décrit par des contraintes d'inégalités linéaires,
      c'est-à-dire qu'il existe une matrice $A$ et un vecteur $b$ tels
      que $Ax\leqslant b$.

    \paragraph{Existence de solutions}
      Pour un tel problème, trois possibilités s'offrent à nous:
      \begin{itemize}
        \item les contraintes sont incompatibles;
        \item la fonction est non majorée sur $C$;
        \item le problème admet un maximum sur $C$.
      \end{itemize}
      Nous savons de plus que $C$ est un polyèdre convexe. Un théorème garantit
      alors que si ce problème a une solution, alors il s'agit d'un de
      ses sommets. Nous allons donc chercher les solutions parmi les sommets de
      $C$.

  \subsubsection{Algorithme du simplexe}
    Le principe de cet algorithme est de considérer un des sommets du polyèdre,
    puis de se déplacer en suivant les arêtes de ce polyèdre en augmentant à
    chaque itération le gain. L'algorithme se terminera lorsque nous nous 
    trouverons sur un sommet, dont tous les sommets adjacents présentent un gain
    plus faible. La convexité du polyèdre nous garantit que le résultat est 
    optimal.

    L'algorithme du simplexe (algorithme~\ref{alg:simpl}) a une complexité dans
    le pire des cas exponentielle, mais en pratique, cet algorithme est
    efficace.
    
    Cet algorithme ne permet pas de maximiser une fonction pour des variables
    entières (par exemple pour connaitre un nombre de produits à produire, donc
    un nombre entier) à produire pour maximiser un gain (bien qu'on pourrait en
    pratique l'utiliser en considérant que la solution optimale entière est
    suffisamment proche de la solution optimale réelle).

    \paragraph{Forme standard et tableau canonique}
      Pour résoudre le problème, la première étape est le mettre sous forme
      standard. Pour cela on ajoute à chaque inéquation $j$ de la forme
      $\sum a_{j,i}x_i \leq 0$ une variable dite d'écart pour la transformer en
      égalité: $\sum a_{j,i}x_i + s_j = 0$ où $s_j \geq 0$.
      
      Les inéquations de la forme $\sum a_ix_i \geq 0$ sont d'abord multipliées
      par $-1$ avant cette étape.
      %todo: et les égalités on en fait quoi ? J'ai essayé en les transformant
      %en deux inégalités <= et >= mais ça marche pas.

      On construit ensuite un tableau dit canonique représentant le problème
      comme suit:
      \begin{itemize}
        \item la première ligne de la matrice est
          $[m_0, m_1, \cdots, m_n, 0, \cdots, 0]$ où les $(m_i)$ sont les
          coefficients du problème $\min \sum m_ix_i$ et à laquelle on ajoute
          autant de $0$ qu'on a ajouté de variables d'écart;
        \item les autres lignes de la matrice sont
          $[a_{j,0}, \cdots, a_{j,n}, 0, \cdots, 0, 1,0, \cdots, 0]$ où les $1$
          sont placés de manière à former une matrice identité (ils
          correspondent aux variables d'écart ajoutées).
      \end{itemize}

    \paragraph{Exemple}
      Considérons le problème suivant: nous pouvons créer 4 produits à partir
      de 3 ressources. Chaque produit rapporte un certain bénéfice et nous
      cherchons à maximiser notre gain.  
      \begin{center}
        \begin{tabular}{|c|cccc|c|}\hline
          & $P_1$ & $P_2$ & $P_3$ & $P_4$ & stock \\ \hline
          $R_A$ & 2 & 4 & 5 & 7 & 72 \\
          $R_B$ & 1 & 1 & 2 & 2 & 17 \\
          $R_C$ & 1 & 2 & 3 & 3 & 24 \\ \hline
          bénéfice & 7 & 9 & 18 & 17 &  \\ \hline
        \end{tabular}
      \end{center}

      La première étape de l'algorithme revient à constuire le tableau suivant,
      en rajoutant les variables d'écart $x_1$, $x_2$ et $x_3$.

      \begin{center}
        \begin{tabular}{|c|ccccccc|c|}\hline
          & $P_1$ & $P_2$ & $P_3$ & $P_4$ & $x_1$ & $x_2$ & $x_3$ & stock \\ \hline
          $R_A$ & 2 & 4 & 5 & 7 & 1 & 0 & 0 & 72 \\
          $R_B$ & 1 & 1 & 2 & 2 & 0 & 1 & 0 & 17 \\
          $R_C$ & 1 & 2 & 3 & 3 & 0 & 0 & 1 & 24 \\ \hline
          bénéfice & 7 & 9 & 18 & 17 & 0 & 0 & 0 & \\ \hline
        \end{tabular}
      \end{center}

      Le produit qui rapporte le plus est $P_3$, et on peut en produire au
      maximum 8 (c'est $\underset{i}{\text{argmin}}
      \frac{\text{stock}(i)}{P_3(i)}$). On va donc en produire le plus
      possible, puis mettre à jour le tableau pour aboutir au tableau suivant:

      \begin{center}
        \begin{tabular}{|c|ccccccc|c|}\hline
          & $P_1$ & $P_2$ & $P_3$ & $P_4$ & $x_1$ & $x_2$ & $x_3$ & stock \\ \hline
          $R_A$ & 1/3 & 2/3 & 0 & 2 & 1 & 0 & -5/3 & 2 \\
          $R_B$ & 1/3 & -1/3 & 0 & 0 & 0 & 1 & -2/3 & 1 \\
          $R_C$ & 1/3 & 2/3 & 1 & 1 & 0 & 0 & 1/3 & 8 \\ \hline
          bénéfice & 1 & -3 & 0 & -1 & 0 & 0 & -6 & -144 \\ \hline
        \end{tabular}
      \end{center}

      Dans la case en bas à gauche se trouve l'opposé du gain. Si on
      recommence, on va donc produire $P_1$ (on en produira $1/3$). Le prochain
      tableau sera donc le suivant:

      \begin{center}
        \begin{tabular}{|c|ccccccc|c|}\hline
          & $P_1$ & $P_2$ & $P_3$ & $P_4$ & $x_1$ & $x_2$ & $x_3$ & stock \\ \hline
          $R_A$ & 0 & 1 & 0 & 2 & 1 & -1 & -1 & 1 \\
          $R_B$ & 1 & -1 & 0 & 0 & 0 & 3 & -2 & 3 \\
          $R_C$ & 0 & 1 & 1 & 1 & 0 & -1 & 1 & 7 \\ \hline
          bénéfice & 0 & -2 & 0 & -1 & 0 & -3 & -4 & -147 \\ \hline
        \end{tabular}
      \end{center}

      On voit maintenant que dans la ligne des bénéfices, les coefficients sont
      tous négatifs ou nuls. Ainsi, quelle que soit la direction dans laquelle on
      se déplace, on baissera nécessairement notre gain. Nous avons donc
      atteint l'optimum : le gain maximal sera de 147 et il sera atteint en
      produisant 3 produits $P_1$ et 7 produits $P_3$.



    % todo:
    %       contraintes négatives
    %       cas non borné
    \paragraph{Dégénérescence}
      Un problème du simplexe est dit dégénéré si plus de deux contraintes vont
      devoir être nulles en un sommet. Graphiquement, cela veut dire
      qu'au moins 3 droites vont se rencontrer en un sommet du polyèdre.

      Ceci va empêcher l'algorithme du simplexe de progresser entre deux
      itérations: il va simplement changer de base. Le problème étant que sur
      des cas particuliers, il pourra changer de base sans progresser, puis
      boucler à l'infini en faisant un cycle sur des bases qui n'améliorent pas
      la solution.

      Pour éviter cela, on pourrait utiliser des règles d'anti-cyclage, dont la
      règle de Bland, qui consiste à choisir judicieusement les variables qu'on
      fera entrer et sortir de la base, dans le cas où il y aurait plusieurs
      possibilités aussi intéressantes les unes que les autres.

